# ç¼“å­˜å’Œå­˜å‚¨é›†æˆè¯´æ˜

## æ¦‚è¿°

æœ¬é¡¹ç›®å°†ç¼“å­˜ç³»ç»Ÿä¸ Parquet æ–‡ä»¶å­˜å‚¨ç´§å¯†é›†æˆï¼Œå®ç°äº†é«˜æ•ˆçš„å»é‡å’Œæ•°æ®ç®¡ç†ã€‚

## å·¥ä½œåŸç†

### 1. åˆå§‹åŒ–æµç¨‹

```python
# 1. é¦–å…ˆåˆå§‹åŒ–å­˜å‚¨
storage = PaperStorage(local_data_dir="data")

# 2. ä»æ‰€æœ‰ Parquet æ–‡ä»¶ä¸­åŠ è½½å·²å­˜å‚¨çš„è®ºæ–‡ ID
stored_paper_ids = storage.load_all_paper_ids()

# 3. ä½¿ç”¨åŠ è½½çš„ ID åˆå§‹åŒ–ç¼“å­˜
cache = PaperCache(initial_ids=stored_paper_ids)
```

è¿™æ ·åšçš„å¥½å¤„ï¼š
- **è‡ªåŠ¨æ¢å¤**ï¼šå³ä½¿ç¼“å­˜æ–‡ä»¶ï¼ˆ`papers_cache.json`ï¼‰ä¸¢å¤±ï¼Œä¹Ÿèƒ½ä» Parquet æ–‡ä»¶æ¢å¤
- **ç»Ÿä¸€æ¥æº**ï¼šParquet æ–‡ä»¶ä½œä¸ºå”¯ä¸€çš„çœŸå®æ•°æ®æº
- **é¿å…é‡å¤**ï¼šç¡®ä¿å·²ä¿å­˜çš„è®ºæ–‡ä¸ä¼šè¢«é‡å¤æ¨é€

### 2. æ•°æ®æµç¨‹

```
çˆ¬å–è®ºæ–‡ â†’ æ£€æŸ¥ç¼“å­˜ â†’ æ¨é€æ–°è®ºæ–‡ â†’ ä¿å­˜åˆ° Parquet â†’ æ›´æ–°ç¼“å­˜
    â†‘                                      â†“
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ä» Parquet åˆå§‹åŒ– â†â”€â”€â”€â”€â”€â”€â”˜
```

### 3. å¢é‡ä¿å­˜

`storage.save_daily_papers()` æ”¯æŒå¢é‡æ›´æ–°ï¼š

```python
# å¦‚æœå½“å¤©çš„æ–‡ä»¶å·²å­˜åœ¨
if filepath.exists():
    # åŠ è½½ç°æœ‰æ•°æ®
    existing_df = pd.read_parquet(filepath)
    # åˆå¹¶æ–°æ—§æ•°æ®
    combined_df = pd.concat([existing_df, new_df])
    # å»é‡ï¼ˆåŸºäº paper_idï¼‰
    combined_df = combined_df.drop_duplicates(subset=['paper_id'], keep='first')
```

ä¼˜åŠ¿ï¼š
- **æ”¯æŒå¤šæ¬¡è¿è¡Œ**ï¼šåŒä¸€å¤©å¯ä»¥å¤šæ¬¡æ£€æŸ¥å¹¶ä¿å­˜æ–°è®ºæ–‡
- **è‡ªåŠ¨å»é‡**ï¼šåŸºäº `paper_id` ç¡®ä¿å”¯ä¸€æ€§
- **æ•°æ®å®Œæ•´æ€§**ï¼šä¿ç•™ç¬¬ä¸€æ¬¡å‡ºç°çš„è®°å½•

### 4. ç¼“å­˜æ›´æ–°ç­–ç•¥

```python
# æ‰¹é‡æ·»åŠ åˆ°ç¼“å­˜ï¼ˆè€Œä¸æ˜¯æ¯ç¯‡è®ºæ–‡å•ç‹¬æ·»åŠ ï¼‰
sent_papers = []
for paper in new_papers:
    if await send_paper(paper):
        sent_papers.append(paper)

# æ‰€æœ‰è®ºæ–‡æ¨é€å®Œæˆåæ‰¹é‡æ›´æ–°ç¼“å­˜
cache.add_batch([p.get_paper_id() for p in sent_papers])
```

ä¼˜åŠ¿ï¼š
- **å‡å°‘ I/O**ï¼šæ‰¹é‡å†™å…¥è€Œä¸æ˜¯é¢‘ç¹ä¿å­˜
- **åŸå­æ€§**ï¼šè¦ä¹ˆå…¨éƒ¨æ›´æ–°ï¼Œè¦ä¹ˆéƒ½ä¸æ›´æ–°
- **æ€§èƒ½ä¼˜åŒ–**ï¼šå‡å°‘æ–‡ä»¶æ“ä½œæ¬¡æ•°

## æ•°æ®ç»“æ„

### Parquet æ–‡ä»¶æ ¼å¼

æ¯ä¸ªè®ºæ–‡è®°å½•åŒ…å«ï¼š

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `paper_id` | string | å”¯ä¸€æ ‡è¯†ç¬¦ï¼ˆä» URL æå–ï¼‰ |
| `title` | string | è®ºæ–‡æ ‡é¢˜ |
| `authors` | string | ä½œè€…åˆ—è¡¨ï¼ˆJSON æ•°ç»„ï¼‰ |
| `abstract` | string | è®ºæ–‡æ‘˜è¦ |
| `url` | string | HuggingFace URL |
| `hero_image` | string | ç¼©ç•¥å›¾ URL |
| `arxiv_url` | string | arXiv URL |
| `collected_at` | string | æ”¶é›†æ—¶é—´ï¼ˆISO 8601ï¼‰ |

### ç¼“å­˜æ–‡ä»¶æ ¼å¼

`papers_cache.json`:

```json
{
  "paper_ids": [
    "2509.25541",
    "2509.25760",
    "..."
  ]
}
```

## å…³é”®æ–¹æ³•

### storage.load_all_paper_ids()

ä»æ‰€æœ‰ Parquet æ–‡ä»¶ä¸­æå–è®ºæ–‡ IDï¼š

```python
def load_all_paper_ids(self) -> set:
    """ä»æ‰€æœ‰ Parquet æ–‡ä»¶ä¸­åŠ è½½å·²å­˜å‚¨çš„è®ºæ–‡ ID"""
    paper_ids = set()
    
    # éå† data/YYYY/MM/*.parquet
    for year_dir in self.local_data_dir.iterdir():
        for month_dir in year_dir.iterdir():
            files = list(month_dir.glob("papers_*.parquet"))
            for file in files:
                df = pd.read_parquet(file, columns=['paper_id'])
                paper_ids.update(df['paper_id'].tolist())
    
    return paper_ids
```

ç‰¹ç‚¹ï¼š
- **åªè¯»å– paper_id åˆ—**ï¼šä¼˜åŒ–æ€§èƒ½ï¼Œä¸åŠ è½½å®Œæ•´æ•°æ®
- **éå†æ‰€æœ‰æ–‡ä»¶**ï¼šç¡®ä¿ä¸é—æ¼ä»»ä½•å†å²æ•°æ®
- **è¿”å›é›†åˆ**ï¼šè‡ªåŠ¨å»é‡

### cache.__init__(initial_ids)

æ”¯æŒä»å¤–éƒ¨æ•°æ®åˆå§‹åŒ–ï¼š

```python
def __init__(self, cache_file: str = "papers_cache.json", initial_ids: Set[str] = None):
    # å…ˆåŠ è½½ JSON ç¼“å­˜æ–‡ä»¶
    self.cached_ids = self._load_cache()
    
    # åˆå¹¶ä»å­˜å‚¨åŠ è½½çš„ ID
    if initial_ids:
        self.cached_ids.update(initial_ids)
        self._save_cache()
```

## ä½¿ç”¨ç¤ºä¾‹

### æµ‹è¯•é›†æˆ

```bash
python tests/test_cache_storage.py
```

è¾“å‡ºï¼š
```
ğŸ§ª æµ‹è¯•ç¼“å­˜å’Œå­˜å‚¨é›†æˆ

æ­¥éª¤ 1: ä»å­˜å‚¨åŠ è½½è®ºæ–‡ ID
ğŸ“š ä»å­˜å‚¨ä¸­åŠ è½½äº† 57 ä¸ªè®ºæ–‡ ID
  âœ“ åŠ è½½äº† 57 ä¸ªè®ºæ–‡ ID

æ­¥éª¤ 2: ç”¨å­˜å‚¨æ•°æ®åˆå§‹åŒ–ç¼“å­˜
âœ… ç¼“å­˜å·²åˆå§‹åŒ–ï¼Œå…± 57 ä¸ªè®ºæ–‡ ID
  âœ“ ç¼“å­˜å¤§å°: 57

æ­¥éª¤ 3: æµ‹è¯•ç¼“å­˜æŸ¥è¯¢
  æµ‹è¯• ID: 2509.25541
  æ˜¯å¦åœ¨ç¼“å­˜ä¸­: True
  æµ‹è¯•å‡ ID: fake_paper_id_12345
  æ˜¯å¦åœ¨ç¼“å­˜ä¸­: False

âœ… æµ‹è¯•å®Œæˆï¼
```

## ä¼˜åŠ¿æ€»ç»“

1. **æ•°æ®ä¸€è‡´æ€§**ï¼šParquet æ–‡ä»¶æ˜¯å”¯ä¸€çš„æ•°æ®æº
2. **è‡ªåŠ¨æ¢å¤**ï¼šç¼“å­˜ä¸¢å¤±æ—¶è‡ªåŠ¨ä»å­˜å‚¨é‡å»º
3. **å¢é‡æ›´æ–°**ï¼šæ”¯æŒå¤šæ¬¡è¿è¡Œï¼Œè‡ªåŠ¨å»é‡
4. **æ€§èƒ½ä¼˜åŒ–**ï¼šæ‰¹é‡æ“ä½œï¼Œå‡å°‘ I/O
5. **é•¿æœŸå­˜å‚¨**ï¼šParquet æ ¼å¼é«˜æ•ˆå‹ç¼©ï¼ˆ57 ç¯‡è®ºæ–‡ä»… 0.07 MBï¼‰
6. **æ˜“äºç»´æŠ¤**ï¼šæ¸…æ™°çš„æ•°æ®æµç¨‹å’ŒèŒè´£åˆ†ç¦»

## æ•…éšœæ¢å¤

å¦‚æœç¼“å­˜æ–‡ä»¶æŸåæˆ–ä¸¢å¤±ï¼š

```bash
# åˆ é™¤ç¼“å­˜æ–‡ä»¶
rm papers_cache.json

# é‡æ–°å¯åŠ¨ Botï¼Œè‡ªåŠ¨ä» Parquet æ–‡ä»¶æ¢å¤
python main.py
```

è¾“å‡ºï¼š
```
ğŸ“š ä»å­˜å‚¨ä¸­åŠ è½½äº† 57 ä¸ªè®ºæ–‡ ID
âœ… ç¼“å­˜å·²åˆå§‹åŒ–ï¼Œå…± 57 ä¸ªè®ºæ–‡ ID
```

## æœªæ¥ä¼˜åŒ–

- [ ] æ·»åŠ å®šæœŸæ¸…ç†æ—§ç¼“å­˜çš„æœºåˆ¶
- [ ] æ”¯æŒä» S3 è¿œç¨‹åŠ è½½è®ºæ–‡ ID
- [ ] å®ç°åˆ†å¸ƒå¼ç¼“å­˜ï¼ˆRedisï¼‰
- [ ] æ·»åŠ ç¼“å­˜é¢„çƒ­åŠŸèƒ½
